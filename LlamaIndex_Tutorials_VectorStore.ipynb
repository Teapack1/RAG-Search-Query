{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q openai\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate\n",
        "!pip install -q optimum[exporters]\n",
        "!pip install -q InstructorEmbedding\n",
        "!pip install -q sentence_transformers\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGOAxDUvKlE",
        "outputId": "0a3e60f4-603e-49a5-dce7-852b73770392"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index chromadb --quiet\n",
        "!pip install -q chromadb\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q pydantic==1.10.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install -q llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3LYEnctgbBWA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python-dotenv could not parse statement starting at line 6\n",
            "Python-dotenv could not parse statement starting at line 7\n",
            "Python-dotenv could not parse statement starting at line 8\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # This loads the variables from .env into the environment\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "482wzQ6mvYxS"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core.storage.storage_context import StorageContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from IPython.display import Markdown, display\n",
        "import chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8pfCTvG9vY8m"
      },
      "outputs": [],
      "source": [
        "# define embedding function\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MPhHSUtnvY_c"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\n",
        "    \"data\"\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jlgXGp47cu"
      },
      "source": [
        "# CHROMA-DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FLmWj6-dwVyN"
      },
      "outputs": [],
      "source": [
        "# create client and a new collection\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "chroma_collection = chroma_client.create_collection(\"ulstore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zBzlbcwLq_"
      },
      "source": [
        "### Set up ChromaVectorStore and load in data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g1KwBHHuwKyD"
      },
      "outputs": [],
      "source": [
        "# set up ChromaVectorStore and load in data\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TPDtjS5P4fn2"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XnwdnuZn4frc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\uzivatel\\AppData\\Local\\Temp\\ipykernel_8700\\3553016389.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
          ]
        }
      ],
      "source": [
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Psv-DFtX4ful"
      },
      "outputs": [],
      "source": [
        "\n",
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "M9KHTQG8wK3_",
        "outputId": "ed5ba2d9-fde5-4772-97fa-a29f0987201a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "A Class 2 circuit is a type of power supply that meets specific safety requirements. It is characterized by having a maximum output voltage of 42.4 V peak AC (30 V RMS) or 60 V DC. Class 2 circuits are designed to limit the risk of electric shock and fire hazards. Additionally, they have no direct electrical connection between the input and output, typically achieved through the use of transformers, optical isolators, or other suitable means."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is class 2 circuit and what are its propperties?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            What cable do I use to hang a 1.5kg heavy luminaire on?\n",
        "            What is the minimal gauge of live wires ?\n",
        "            What flamability fequirements do plastic enclosure have to meet ?\n",
        "            What is class 2 circuit and what are its propperties?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFasbpZJ0TUb"
      },
      "source": [
        "### How to Persist: Saving to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B5i5lxQrvZCu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\uzivatel\\AppData\\Local\\Temp\\ipykernel_8700\\1637600030.py:10: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(embed_model=embed_model,\n"
          ]
        }
      ],
      "source": [
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "\n",
        "chroma_collection = db.get_or_create_collection(\"512_store\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model,\n",
        "                                               chunk_size=512,\n",
        "                                               chunk_overlap=128)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V69BQgST6aId"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9Z8BmH1BaM"
      },
      "source": [
        "### Load from Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ytlj_EPVvZFm"
      },
      "outputs": [],
      "source": [
        "# load from disk\n",
        "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "chroma_collection = db2.get_or_create_collection(\"512_store\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store,\n",
        "    service_context=service_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "nJ1bh3zh1OD7",
        "outputId": "52d8adfa-0b78-4f6b-b3b8-c97f3ee2aad5"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The minimal thickness of the metallic enclosure sheet is 0.66 mm (0.026 in) for unreinforced steel and extruded aluminum at the opening for conduit connection."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is the minimal thickness of the matalic enclosure sheet?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-qGk3n-7Suh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWGp_dP6mPY"
      },
      "source": [
        "# PINECONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOr6p10m1OJ0"
      },
      "outputs": [],
      "source": [
        "!pip install -q pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_nzoUZh1OM8"
      },
      "outputs": [],
      "source": [
        "import pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEzw43BoC5P7"
      },
      "outputs": [],
      "source": [
        "os.environ['PINECONE_API_KEY'] = \"PINECONE_API_KEY\"\n",
        "os.environ['PINECONE_ENVIRONMENT'] = 'gcp-starter'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTokcpnr1OP0"
      },
      "outputs": [],
      "source": [
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ['PINECONE_API_KEY'],\n",
        "    environment=os.environ['PINECONE_ENVIRONMENT']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwAPbSv8Dy6I"
      },
      "outputs": [],
      "source": [
        "# create the index if it does not exist already\n",
        "index_name = 'llamaindex'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=768,\n",
        "        metric='cosine'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmA9O7nqENlK",
        "outputId": "e8735c6e-2c52-44e1-c786-6b6eeecdf171"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "IndexDescription(name='llamaindex', metric='cosine', replicas=1, dimension=768.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pinecone_index = pinecone.Index(\"llamaindex\")\n",
        "pinecone.describe_index(\"llamaindex\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kltmj58fENod"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores import PineconeVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL9KY3P8ENrl"
      },
      "outputs": [],
      "source": [
        "# set add_sparse_vector=True to compute sparse vectors during upsert\n",
        "from llama_index.storage.storage_context import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwT2d7oFENu8"
      },
      "outputs": [],
      "source": [
        "vector_store = PineconeVectorStore(\n",
        "    pinecone_index=pinecone_index,\n",
        "    # add_sparse_vector=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTzwIpi5ENy1"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b58206b26c764c02a5dcc77a022b7b38",
            "6afddafd20254a0aa4895e311000f104",
            "f1e98261f3ce46139ae4b037bd0ea918",
            "f21284f9f56040f3abc9585bdd99816c",
            "a0a9ec8e01254b63a7659c4476fbc5c7",
            "e3c2934caa814a4a97b84f4d28a15686",
            "7427c25da71547f0b03dbeba6b01378e",
            "d93420720cb945e6a5094781ec5c8ba8",
            "60b9f3faaa52444498b3f5e7d5ba058e",
            "8de1e4e251d240e281f1921ab7913fc9",
            "d401f7ed4b404fecb9239fa5b2aeb675"
          ]
        },
        "id": "WKW4s4YoEN1V",
        "outputId": "06674e1e-a7c9-41f5-fc28-822277a02dd7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b58206b26c764c02a5dcc77a022b7b38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upserted vectors:   0%|          | 0/55 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yQ2waFYsFOfu",
        "outputId": "c589b140-6b7a-4b15-c0f1-1c28e428d0de"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Big-Bench Hard is a suite of 23 challenging tasks that were introduced to measure the capabilities and limitations of large language models. These tasks are specifically designed to be difficult and have been selected based on the fact that prior language models did not outperform the average human-rater on them. The evaluation of Big-Bench Hard tasks is done using standard zero-shot prompting, without the use of any labeled examples."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is Big-Bench Hard test?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Y1fjC4FOjD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_17Kx7aFOmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXSbsstFOpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60b9f3faaa52444498b3f5e7d5ba058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6afddafd20254a0aa4895e311000f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c2934caa814a4a97b84f4d28a15686",
            "placeholder": "​",
            "style": "IPY_MODEL_7427c25da71547f0b03dbeba6b01378e",
            "value": "Upserted vectors: 100%"
          }
        },
        "7427c25da71547f0b03dbeba6b01378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de1e4e251d240e281f1921ab7913fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a9ec8e01254b63a7659c4476fbc5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58206b26c764c02a5dcc77a022b7b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6afddafd20254a0aa4895e311000f104",
              "IPY_MODEL_f1e98261f3ce46139ae4b037bd0ea918",
              "IPY_MODEL_f21284f9f56040f3abc9585bdd99816c"
            ],
            "layout": "IPY_MODEL_a0a9ec8e01254b63a7659c4476fbc5c7"
          }
        },
        "d401f7ed4b404fecb9239fa5b2aeb675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93420720cb945e6a5094781ec5c8ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c2934caa814a4a97b84f4d28a15686": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e98261f3ce46139ae4b037bd0ea918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93420720cb945e6a5094781ec5c8ba8",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b9f3faaa52444498b3f5e7d5ba058e",
            "value": 55
          }
        },
        "f21284f9f56040f3abc9585bdd99816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de1e4e251d240e281f1921ab7913fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d401f7ed4b404fecb9239fa5b2aeb675",
            "value": " 55/55 [02:25&lt;00:00, 37.46it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
