{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q openai\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate\n",
        "!pip install -q optimum[exporters]\n",
        "!pip install -q InstructorEmbedding\n",
        "!pip install -q sentence_transformers\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb\n",
        "!pip install -q pydantic==1.10.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install -q llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3LYEnctgbBWA"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # This loads the variables from .env into the environment\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "482wzQ6mvYxS"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core.storage.storage_context import StorageContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from IPython.display import Markdown, display\n",
        "import chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8pfCTvG9vY8m"
      },
      "outputs": [],
      "source": [
        "# define embedding function\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MPhHSUtnvY_c"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\n",
        "    \"data/english\"\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jlgXGp47cu"
      },
      "source": [
        "# CHROMA-DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FLmWj6-dwVyN"
      },
      "outputs": [
        {
          "ename": "UniqueConstraintError",
          "evalue": "Collection ulstore already exists",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create client and a new collection\u001b[39;00m\n\u001b[0;32m      2\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mEphemeralClient()\n\u001b[1;32m----> 3\u001b[0m chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mulstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\ProjectsPython\\RAG-Search-Query\\venv\\lib\\site-packages\\chromadb\\api\\client.py:198\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Code\\ProjectsPython\\RAG-Search-Query\\venv\\lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Code\\ProjectsPython\\RAG-Search-Query\\venv\\lib\\site-packages\\chromadb\\api\\segment.py:167\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_index_name(name)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m uuid4()\n\u001b[1;32m--> 167\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[0;32m    178\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mcreate_segments(coll)\n",
            "File \u001b[1;32md:\\Code\\ProjectsPython\\RAG-Search-Query\\venv\\lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Code\\ProjectsPython\\RAG-Search-Query\\venv\\lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:225\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[0;32m    220\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[0;32m    221\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    223\u001b[0m         )\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assignment_policy\u001b[38;5;241m.\u001b[39massign_collection(\u001b[38;5;28mid\u001b[39m)\n\u001b[0;32m    228\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    230\u001b[0m     topic\u001b[38;5;241m=\u001b[39mtopic,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    236\u001b[0m )\n",
            "\u001b[1;31mUniqueConstraintError\u001b[0m: Collection ulstore already exists"
          ]
        }
      ],
      "source": [
        "# create client and a new collection\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "chroma_collection = chroma_client.create_collection(\"ulstore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zBzlbcwLq_"
      },
      "source": [
        "### Set up ChromaVectorStore and load in data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g1KwBHHuwKyD"
      },
      "outputs": [],
      "source": [
        "# set up ChromaVectorStore and load in data\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TPDtjS5P4fn2"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XnwdnuZn4frc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ondre\\AppData\\Local\\Temp\\ipykernel_16672\\3553016389.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
          ]
        }
      ],
      "source": [
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Psv-DFtX4ful"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "M9KHTQG8wK3_",
        "outputId": "ed5ba2d9-fde5-4772-97fa-a29f0987201a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The minimal gauge of live wires is not specified in the provided context information."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is the minimal gauge of live wires ?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "            What cable do I use to hang a 1.5kg heavy luminaire on?\n",
        "            What is the minimal gauge of live wires ?\n",
        "            What flamability fequirements do plastic enclosure have to meet ?\n",
        "            What is class 2 circuit and what are its propperties?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFasbpZJ0TUb"
      },
      "source": [
        "### How to Persist: Saving to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B5i5lxQrvZCu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\uzivatel\\AppData\\Local\\Temp\\ipykernel_8700\\1637600030.py:10: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(embed_model=embed_model,\n"
          ]
        }
      ],
      "source": [
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "\n",
        "chroma_collection = db.get_or_create_collection(\"512_store\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model,\n",
        "                                               chunk_size=512,\n",
        "                                               chunk_overlap=128)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V69BQgST6aId"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9Z8BmH1BaM"
      },
      "source": [
        "### Load from Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ytlj_EPVvZFm"
      },
      "outputs": [],
      "source": [
        "# load from disk\n",
        "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "chroma_collection = db2.get_or_create_collection(\"512_store\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store,\n",
        "    service_context=service_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "nJ1bh3zh1OD7",
        "outputId": "52d8adfa-0b78-4f6b-b3b8-c97f3ee2aad5"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The minimal thickness of the metallic enclosure sheet is 0.66 mm (0.026 in) for unreinforced steel and extruded aluminum at the opening for conduit connection."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is the minimal thickness of the matalic enclosure sheet?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-qGk3n-7Suh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWGp_dP6mPY"
      },
      "source": [
        "# PINECONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOr6p10m1OJ0"
      },
      "outputs": [],
      "source": [
        "!pip install -q pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_nzoUZh1OM8"
      },
      "outputs": [],
      "source": [
        "import pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEzw43BoC5P7"
      },
      "outputs": [],
      "source": [
        "os.environ['PINECONE_API_KEY'] = \"PINECONE_API_KEY\"\n",
        "os.environ['PINECONE_ENVIRONMENT'] = 'gcp-starter'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTokcpnr1OP0"
      },
      "outputs": [],
      "source": [
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ['PINECONE_API_KEY'],\n",
        "    environment=os.environ['PINECONE_ENVIRONMENT']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwAPbSv8Dy6I"
      },
      "outputs": [],
      "source": [
        "# create the index if it does not exist already\n",
        "index_name = 'llamaindex'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=768,\n",
        "        metric='cosine'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmA9O7nqENlK",
        "outputId": "e8735c6e-2c52-44e1-c786-6b6eeecdf171"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "IndexDescription(name='llamaindex', metric='cosine', replicas=1, dimension=768.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pinecone_index = pinecone.Index(\"llamaindex\")\n",
        "pinecone.describe_index(\"llamaindex\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kltmj58fENod"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores import PineconeVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL9KY3P8ENrl"
      },
      "outputs": [],
      "source": [
        "# set add_sparse_vector=True to compute sparse vectors during upsert\n",
        "from llama_index.storage.storage_context import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwT2d7oFENu8"
      },
      "outputs": [],
      "source": [
        "vector_store = PineconeVectorStore(\n",
        "    pinecone_index=pinecone_index,\n",
        "    # add_sparse_vector=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTzwIpi5ENy1"
      },
      "outputs": [],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b58206b26c764c02a5dcc77a022b7b38",
            "6afddafd20254a0aa4895e311000f104",
            "f1e98261f3ce46139ae4b037bd0ea918",
            "f21284f9f56040f3abc9585bdd99816c",
            "a0a9ec8e01254b63a7659c4476fbc5c7",
            "e3c2934caa814a4a97b84f4d28a15686",
            "7427c25da71547f0b03dbeba6b01378e",
            "d93420720cb945e6a5094781ec5c8ba8",
            "60b9f3faaa52444498b3f5e7d5ba058e",
            "8de1e4e251d240e281f1921ab7913fc9",
            "d401f7ed4b404fecb9239fa5b2aeb675"
          ]
        },
        "id": "WKW4s4YoEN1V",
        "outputId": "06674e1e-a7c9-41f5-fc28-822277a02dd7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b58206b26c764c02a5dcc77a022b7b38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upserted vectors:   0%|          | 0/55 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yQ2waFYsFOfu",
        "outputId": "c589b140-6b7a-4b15-c0f1-1c28e428d0de"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Big-Bench Hard is a suite of 23 challenging tasks that were introduced to measure the capabilities and limitations of large language models. These tasks are specifically designed to be difficult and have been selected based on the fact that prior language models did not outperform the average human-rater on them. The evaluation of Big-Bench Hard tasks is done using standard zero-shot prompting, without the use of any labeled examples."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is Big-Bench Hard test?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Y1fjC4FOjD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_17Kx7aFOmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXSbsstFOpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60b9f3faaa52444498b3f5e7d5ba058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6afddafd20254a0aa4895e311000f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c2934caa814a4a97b84f4d28a15686",
            "placeholder": "​",
            "style": "IPY_MODEL_7427c25da71547f0b03dbeba6b01378e",
            "value": "Upserted vectors: 100%"
          }
        },
        "7427c25da71547f0b03dbeba6b01378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de1e4e251d240e281f1921ab7913fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a9ec8e01254b63a7659c4476fbc5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b58206b26c764c02a5dcc77a022b7b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6afddafd20254a0aa4895e311000f104",
              "IPY_MODEL_f1e98261f3ce46139ae4b037bd0ea918",
              "IPY_MODEL_f21284f9f56040f3abc9585bdd99816c"
            ],
            "layout": "IPY_MODEL_a0a9ec8e01254b63a7659c4476fbc5c7"
          }
        },
        "d401f7ed4b404fecb9239fa5b2aeb675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93420720cb945e6a5094781ec5c8ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c2934caa814a4a97b84f4d28a15686": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e98261f3ce46139ae4b037bd0ea918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93420720cb945e6a5094781ec5c8ba8",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b9f3faaa52444498b3f5e7d5ba058e",
            "value": 55
          }
        },
        "f21284f9f56040f3abc9585bdd99816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de1e4e251d240e281f1921ab7913fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d401f7ed4b404fecb9239fa5b2aeb675",
            "value": " 55/55 [02:25&lt;00:00, 37.46it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
